\chapter{Hardwareansteuerung}

    In folgendem Kapitel wird die Hardwareansteuerung des Roboters dokumentiert.

    \section{Behaviour}

        Um Behaviour, welche in dem Roboter abgespeichert sind, starten und
        stoppen zu können, wird zu Beginn des Programmes ein
        "`Behaviour-Objekt'' mit der \ac{IP}-Adresse als Parameter instanziiert
        (\autoref{lst:initbeh}).

\begin{lstlisting}[language=c++,
                   caption={Initialisierung Behaviour},
                   label={lst:initbeh}]
behaviour::Behaviour behaviourProxy(robotIp);
\end{lstlisting}

        Um später per Namespace auf die verschiedenen Behaviour zugereifen zu
        können ohne den Namen der Behaviour wissen zu müssen, werden die
        Behaviour mit einem Enumerator-Wert (\autoref{lst:behenum}) und deren
        richtigen Namen in einer Map gespeichert (\autoref{lst:behmap}).

\begin{lstlisting}[language=c++,
                   caption={Behaviour Enumerator},
                   label={lst:behenum}]
enum BehaviorID {
    Stand_up,
    Pickup,
    Throw,
    Register_Color,
    Search_Position,
    Won,
    Lost,
    Turn_Around,
    Greetings,
    ALL
};
\end{lstlisting}

        \autoref{lst:behenum} sichert zur Compiletime, dass die Behaviour
        richtig referenziert werden (Konzept des Single-Point-of-Failure).

        Um die Behaviour nun starten und stoppen zu können wurden zusätzliche
        Hilfsfunktionen erstellt
        (\autoref{lst:behstart}, \autoref{lst:behstop}).

    \section{Navigation}

        Um den Roboter steuern zu können, wird zu Beginn des Programmes ein
        Navigation-Objekt mit der \ac{IP}-Adresse als Parameter instanziiert
        (\autoref{lst:navinst}).

\begin{lstlisting}[language=c++,
                   caption={Navigation Instanziierung},
                   label={lst:navinst}]
navigation::Navigation navigationProxy(robotIp);
\end{lstlisting}

        Für die Steuerung wird in \autoref{lst:navmove} eine Funktion mit drei
        Parametern definiert.

\begin{lstlisting}[language=c++,
                   caption={Funktion: "`moveTo''},
                   label={lst:navmove}]
void Navigation::moveTo(const float x, const float y, const float rad) {
    globalNavProxy->moveTo(x, y, rad);
}
\end{lstlisting}

    \section{ImageLoader}

        Um ein Bild von dem Roboter auf den Steuer-Computer übertragen zu können
        wird zu Beginn des Programms ein "`ImageLoader''-Objekt instanziiert
        (\autoref{lst:imginst}).
        Dieses wird mit der \ac{IP}-Adresse und einer Pfadangabe zur Speicherung
        des Bildes instanziiert.

\begin{lstlisting}[language=c++,
                   caption={ImageLoader Instanziierung},
                   label={lst:imginst}]
imgloader::ImageLoader imageLoaderProxy(robotIp, pathToFile);
\end{lstlisting}

        Zu Beginn muss der VideoStream des NAO-Roboters "`angemeldet'' werden.
        Anschließend kann das Bild auf den Computer übertragen, und in ein
        Bild-Objekt von OpenCV gespeichert werden.
        Nach dem das Bild auf dem Computer gespeichert wurde, muss der
        VideoStream „abgemeldet“ und das Bild über die OpenCV-Funktion
        "`imwrite'' auf den Computer gespeichert werden.
        Das SDK bietet sechs unterschiedliche Bildqualitäten an, wie in
        \autoref{tbl:qualities} gelistet.

        \begin{table}[h]
            \caption{SDK Bildqualität}
            \label{tbl:qualities}
            \begin{center}
                \begin{tabular}[]{| l | l | l |}
                    AL::kQQQQVGA & 8 & Image of $40 * 30px$ \\
                    AL::kQQQVGA  & 7 & Image of $80 * 60px$ \\
                    AL::kQQVGA   & 0 & Image of $160 * 120px$ \\
                    AL::kQVGA    & 1 & Image of $320 * 240px$ \\
                    AL::kVGA     & 2 & Image of $640 * 480px$ \\
                    AL::k4VGA    & 3 & Image of $1280 * 960px$ \\
                \end{tabular}
            \end{center}
        \end{table}

\begin{lstlisting}[language=c++,
                   caption={Funktion: "`ImageLoader::getImage()''},
                   label={lst:imgget}]
void ImageLoader::getImage(){
    const std::string clientName = globalVideoProxy->subscribe("imgloader", AL::k4VGA, AL::kBGRColorSpace, 5);
    cv::Mat imgHeader = cv::Mat(cv::Size(1280, 960), CV_8UC3);
    AL::ALValue img = globalVideoProxy->getImageRemote(clientName);
    imgHeader.data = (uchar*) img[6].GetBinary();
    globalVideoProxy->releaseImage(clientName);
    globalVideoProxy->unsubscribe(clientName);
    cv::imwrite(pathToFile, imgHeader);
}
\end{lstlisting}

\chapter{Main-Funktion}

    Um mit dem Roboter Sprachausgaben tätigen zu können, wird neben dem
    Behaviour-, Navigation- und ImageLoader-Objekt ein
    ALTextToSpeechProxy-Objekt instanziiert.
    Dieses wird im Anschluss mit Lautstärke und Sprache konfiguriert.

\begin{lstlisting}[language=c++,
                   caption={Instanziierung ALTextToSpeechProxy},
                   label={lst:alttts}]
AL::ALTextToSpeechProxy speakProxy(robotIp, 9559);
speakProxy.setLanguage("German");
speakProxy.setVolume(0.3);
behaviorProxy.startBehavior(behavior::Greetings);
speakProxy.say("Lass uns beginnen, ich fange an");
\end{lstlisting}

    Bevor der Spielzyklus beginnt, begrüßt der NAO-Roboter das Publikum mit
    dem Behavior „Greetings“ und teilt mit, dass er nun bereit ist
    anzufangen (\autoref{lst:alttts}).

    Der NAO-Roboter und somit auch der Spielzyklus beginnt damit, dass der
    Roboter den Würfel aufhebt und auf eine Eingabe wartet, damit er
    in die richtige Position für einen Wurf gebracht werden kann.

    Nach dem eine Eingabe getätigt wurde, wirft der Roboter den Würfel.
    Nun begibt sich der Roboter in die Suchposition, sagt dass
    er nun mit der Suche des Würfels beginnt und schießt ein Foto.

    Zu Beginn sucht der Roboter in der Ausgangsposition nach dem Würfel.
    Wenn der Würfel nicht gefunden werden kann, dreht sich der Roboter um
    60 Grad nach links.
    Dort schießt er erneut ein Foto und führt eine Suche durch.
    Bei erneutem Fehlschlag dreht sich der Roboter um 120 Grad nach rechts,
    schießt ein Foto und führt eine Suche durch.
    Wenn der Würfel bis dahin noch nicht gefunden wurde, liegt der Würfel
    mit größter Wahrscheinlichkeit genau vor den Füßen des Roboters, und somit
    außerhalb des Sichtbereichs des Roboters.
    Um dieses Problem zu umgehen, dreht sich der Roboter in die
    Ausgangsposition und läuft 20 Zentimeter nach hinten.
    Dort schießt er ein Bild und analysiert es.
    Wenn dort kein Würfel gefunden werden kann, wird das Programm
    mit einer Ausnahme beendet.
    Bei erfolgreicher Suche werden die x- und y-Koordinaten sowie der Winkel
    berechnet und in die lokalen Variablen gespeichert.
    Im Anschluss wird eine Sprachausgabe getätigt.

    Nachdem der Würfel gefunden wurde, werden die Koordinaten von
    Meter in Zentimeter umgerechnet.
    Zudem werden die Koordinaten und der Winkel dem Rutschen des Roboters
    angepasst.
    Nachdem alle Werte umgerechnet sind, läuft der
    Roboter zunächst den kompletten Weg in y-Richtung und anschließend den
    halben Weg in x-Richtung.
    Dies soll mögliche Abweichungen des Roboters durch Aufteilung des Laufweges
    kompensieren.

    Nun werden die zwei letzten Schritte wiederholt.
    Allerdings wird nun nicht die Hälfte des Weges gelaufen, sondern der
    komplette restlich Weg.

    Jetzt befindet sich der Roboter vor dem Würfel.
    Er signalisiert mit einer Sprachausgabe, dass er nun die Zahl welche er
    gewürfelt hat versucht herauszufinden.
    Hierbei wird das Behavior„"`Register\_Color'' aufgerufen und
    anschließend ein Bild aufgenommen.
    Danach wird analysiert welche Zahl gewürfelt wurde.
    Das Ergebnis der Analyse wird anschließend in den Spielalgorithmus
    eingespeist.
    Die gewürfelte Zahl wird per Sprachausgabe bekannt gegeben.
    Nach der Ersten Runde gibt der Roboter zudem den aktuellen Spielstand per
    Sprachausgabe bekannt.
    Im Anschluss errechnet der Roboter ob er weiter spielen soll.
    Sollte dies zutreffen, gibt der Roboter dies wiederum per Sprachausgabe
    bekannt und der Spielzyklus beginnt von vorne.
    Sollte dies nicht zutreffen wird das Spiel beendet.

    Nun gibt der Roboter bekannt, dass er mit Würfeln fertig ist.
    Es wird überprüft, ob der Roboter gewonnen oder verloren hat, oder ob der
    Gegenspieler (die Bank) einmal würfeln darf.
    Wenn der Gegenspieler einmal würfeln darf, gibt der Roboter dies per
    Sprachausgabe bekannt und wartet bis eine Eingabe getätigt wird.
    Nachdem die Eingabe getätigt wurde beginnt der Roboter wie zuvor den
    Würfel zu suchen.
    Wenn der Roboter den Würfel gefunden hat, gibt er dies bekannt und versucht
    zu erkennen, welche Zahl der Gegenspieler gewürfelt hat.
    Anschließend gibt der Roboter bekannt welche Zahl er erkannt hat und es wird
    errechnet ob der Roboter oder der Gegenspieler gewonnen hat.

    Sollte der Gegenspieler gewonnen haben, wird das Behavior "`Lost''
    ausgeführt und der Roboter gibt bekannt, dass der Gegenspieler gewonnen hat.
    Wenn der Roboter gewonnen hat, wird das Behavior "`Won'' ausgeführt und
    das Programm wird beendet.
